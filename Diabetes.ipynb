{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Diabetes.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vyzkhd/Deep-Learning-Projects/blob/master/Diabetes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQVb-2q5wdx8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai.vision import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMKV8fk1wlb0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "912b8236-2e4e-4b41-9d0e-4d23f2bbc86a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "root_dir = \"/content/gdrive/My Drive/\"\n",
        "base_dir = root_dir + 'Projects/'"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWLPbglDx95m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = Path(base_dir+'data/Diabetes')\n",
        "path.mkdir(parents=True,exist_ok=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "At-gEqJwyVtj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "681d2244-01de-4fb2-992e-6250095b6d97"
      },
      "source": [
        "path.ls()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('/content/gdrive/My Drive/Projects/data/Diabetes/diabetes.csv')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "es8cKt5kzz3n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(path/'diabetes.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CunJWDZ10Vzv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "2678b2e8-c450-4b1d-a6cd-83f88508288f"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  ...  DiabetesPedigreeFunction  Age  Outcome\n",
              "0            6      148             72  ...                     0.627   50        1\n",
              "1            1       85             66  ...                     0.351   31        0\n",
              "2            8      183             64  ...                     0.672   32        1\n",
              "3            1       89             66  ...                     0.167   21        0\n",
              "4            0      137             40  ...                     2.288   33        1\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2zBKK6K2cGz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "c8d01f7b-fbb0-4463-8cd7-060f4dde15cd"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 768 entries, 0 to 767\n",
            "Data columns (total 9 columns):\n",
            "Pregnancies                 768 non-null int64\n",
            "Glucose                     768 non-null int64\n",
            "BloodPressure               768 non-null int64\n",
            "SkinThickness               768 non-null int64\n",
            "Insulin                     768 non-null int64\n",
            "BMI                         768 non-null float64\n",
            "DiabetesPedigreeFunction    768 non-null float64\n",
            "Age                         768 non-null int64\n",
            "Outcome                     768 non-null int64\n",
            "dtypes: float64(2), int64(7)\n",
            "memory usage: 54.1 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBQXO_wq3Ura",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "4c66a623-01cf-4ebd-b666-bebe0c28f6a0"
      },
      "source": [
        "for col in df.columns:\n",
        "  missing_rows = df[df[col]==0].shape[0]\n",
        "  print(col+' : '+str(missing_rows))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pregnancies : 111\n",
            "Glucose : 5\n",
            "BloodPressure : 35\n",
            "SkinThickness : 227\n",
            "Insulin : 374\n",
            "BMI : 11\n",
            "DiabetesPedigreeFunction : 0\n",
            "Age : 0\n",
            "Outcome : 500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4J5f79Cm3xDs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.Glucose = df.Glucose.replace(0,np.nan)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tja6FoOk4Qyb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.BloodPressure = df.BloodPressure.replace(0,np.nan)\n",
        "df.Insulin = df.Insulin.replace(0,np.nan)\n",
        "df.BMI = df.BMI.replace(0,np.nan)\n",
        "df.SkinThickness = df.SkinThickness.replace(0,np.nan)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eCvGVNF4wDh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.Glucose = df.Glucose.fillna(df.Glucose.mean())\n",
        "df.BloodPressure = df.BloodPressure.fillna(df.BloodPressure.mean())\n",
        "df.Insulin = df.Insulin.fillna(df.Insulin.mean())\n",
        "df.BMI = df.BMI.fillna(df.BMI.mean())\n",
        "df.SkinThickness = df.SkinThickness.fillna(df.SkinThickness.mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoGT7XWh5X6D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "af6d629d-5b1e-44b9-83ba-e5127f0ea4f9"
      },
      "source": [
        "df.sample(10)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>664</th>\n",
              "      <td>6</td>\n",
              "      <td>115.0</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>39.00000</td>\n",
              "      <td>155.548223</td>\n",
              "      <td>33.7</td>\n",
              "      <td>0.245</td>\n",
              "      <td>40</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>2</td>\n",
              "      <td>92.0</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>28.00000</td>\n",
              "      <td>155.548223</td>\n",
              "      <td>31.6</td>\n",
              "      <td>0.130</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137</th>\n",
              "      <td>0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>25.00000</td>\n",
              "      <td>92.000000</td>\n",
              "      <td>28.7</td>\n",
              "      <td>0.532</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223</th>\n",
              "      <td>7</td>\n",
              "      <td>142.0</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>33.00000</td>\n",
              "      <td>190.000000</td>\n",
              "      <td>28.8</td>\n",
              "      <td>0.687</td>\n",
              "      <td>61</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>363</th>\n",
              "      <td>4</td>\n",
              "      <td>146.0</td>\n",
              "      <td>78.000000</td>\n",
              "      <td>29.15342</td>\n",
              "      <td>155.548223</td>\n",
              "      <td>38.5</td>\n",
              "      <td>0.520</td>\n",
              "      <td>67</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>519</th>\n",
              "      <td>6</td>\n",
              "      <td>129.0</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>7.00000</td>\n",
              "      <td>326.000000</td>\n",
              "      <td>19.6</td>\n",
              "      <td>0.582</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>587</th>\n",
              "      <td>6</td>\n",
              "      <td>103.0</td>\n",
              "      <td>66.000000</td>\n",
              "      <td>29.15342</td>\n",
              "      <td>155.548223</td>\n",
              "      <td>24.3</td>\n",
              "      <td>0.249</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>710</th>\n",
              "      <td>3</td>\n",
              "      <td>158.0</td>\n",
              "      <td>64.000000</td>\n",
              "      <td>13.00000</td>\n",
              "      <td>387.000000</td>\n",
              "      <td>31.2</td>\n",
              "      <td>0.295</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>286</th>\n",
              "      <td>5</td>\n",
              "      <td>155.0</td>\n",
              "      <td>84.000000</td>\n",
              "      <td>44.00000</td>\n",
              "      <td>545.000000</td>\n",
              "      <td>38.7</td>\n",
              "      <td>0.619</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>643</th>\n",
              "      <td>4</td>\n",
              "      <td>90.0</td>\n",
              "      <td>72.405184</td>\n",
              "      <td>29.15342</td>\n",
              "      <td>155.548223</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0.610</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Pregnancies  Glucose  ...  Age  Outcome\n",
              "664            6    115.0  ...   40        1\n",
              "96             2     92.0  ...   24        0\n",
              "137            0     93.0  ...   22        0\n",
              "223            7    142.0  ...   61        0\n",
              "363            4    146.0  ...   67        1\n",
              "519            6    129.0  ...   60        0\n",
              "587            6    103.0  ...   29        0\n",
              "710            3    158.0  ...   24        0\n",
              "286            5    155.0  ...   34        0\n",
              "643            4     90.0  ...   31        0\n",
              "\n",
              "[10 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tjdFQDT5aHo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import preprocessing\n",
        "df2 = preprocessing.scale(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GUkaLTg5pHk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df2 = pd.DataFrame(df2,columns=df.columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqO2M6-G5tJP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "282d37f3-de5e-46ab-f44c-6a914f9b0e90"
      },
      "source": [
        "df2.sample(10)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>0.046014</td>\n",
              "      <td>-0.351352</td>\n",
              "      <td>-0.033518</td>\n",
              "      <td>2.031433e+00</td>\n",
              "      <td>6.055591e-01</td>\n",
              "      <td>0.675703</td>\n",
              "      <td>2.772843</td>\n",
              "      <td>1.936522</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>642</th>\n",
              "      <td>0.639947</td>\n",
              "      <td>0.832231</td>\n",
              "      <td>0.628269</td>\n",
              "      <td>8.087936e-16</td>\n",
              "      <td>-3.345079e-16</td>\n",
              "      <td>-0.430447</td>\n",
              "      <td>-0.887541</td>\n",
              "      <td>1.425995</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>-0.547919</td>\n",
              "      <td>-1.206162</td>\n",
              "      <td>-0.612582</td>\n",
              "      <td>8.087936e-16</td>\n",
              "      <td>-3.345079e-16</td>\n",
              "      <td>1.039569</td>\n",
              "      <td>1.383588</td>\n",
              "      <td>-0.531023</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>289</th>\n",
              "      <td>0.342981</td>\n",
              "      <td>-0.449984</td>\n",
              "      <td>-0.033518</td>\n",
              "      <td>1.576123e+00</td>\n",
              "      <td>-9.480083e-01</td>\n",
              "      <td>0.530157</td>\n",
              "      <td>-0.630831</td>\n",
              "      <td>-0.020496</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>676</th>\n",
              "      <td>1.530847</td>\n",
              "      <td>1.128126</td>\n",
              "      <td>1.124610</td>\n",
              "      <td>8.087936e-16</td>\n",
              "      <td>-3.345079e-16</td>\n",
              "      <td>-1.114514</td>\n",
              "      <td>-0.730495</td>\n",
              "      <td>1.681259</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270</th>\n",
              "      <td>1.827813</td>\n",
              "      <td>-0.680125</td>\n",
              "      <td>1.124610</td>\n",
              "      <td>8.931573e-01</td>\n",
              "      <td>-3.345079e-16</td>\n",
              "      <td>1.912845</td>\n",
              "      <td>2.005732</td>\n",
              "      <td>0.404942</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>448</th>\n",
              "      <td>-1.141852</td>\n",
              "      <td>-0.581493</td>\n",
              "      <td>-0.695306</td>\n",
              "      <td>8.931573e-01</td>\n",
              "      <td>-1.077472e+00</td>\n",
              "      <td>0.166292</td>\n",
              "      <td>0.115138</td>\n",
              "      <td>-0.956462</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>636</th>\n",
              "      <td>0.342981</td>\n",
              "      <td>-0.581493</td>\n",
              "      <td>0.131929</td>\n",
              "      <td>8.087936e-16</td>\n",
              "      <td>-3.345079e-16</td>\n",
              "      <td>-0.532330</td>\n",
              "      <td>-0.963044</td>\n",
              "      <td>1.255820</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>219</th>\n",
              "      <td>0.342981</td>\n",
              "      <td>-0.318475</td>\n",
              "      <td>-0.529859</td>\n",
              "      <td>8.087936e-16</td>\n",
              "      <td>-3.345079e-16</td>\n",
              "      <td>0.777585</td>\n",
              "      <td>-0.636871</td>\n",
              "      <td>0.660206</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>664</th>\n",
              "      <td>0.639947</td>\n",
              "      <td>-0.219843</td>\n",
              "      <td>-1.026200</td>\n",
              "      <td>1.120812e+00</td>\n",
              "      <td>-3.345079e-16</td>\n",
              "      <td>0.180846</td>\n",
              "      <td>-0.685193</td>\n",
              "      <td>0.575118</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Pregnancies   Glucose  ...       Age  Outcome\n",
              "39      0.046014 -0.351352  ...  1.936522        1\n",
              "642     0.639947  0.832231  ...  1.425995        1\n",
              "104    -0.547919 -1.206162  ... -0.531023        0\n",
              "289     0.342981 -0.449984  ... -0.020496        0\n",
              "676     1.530847  1.128126  ...  1.681259        1\n",
              "270     1.827813 -0.680125  ...  0.404942        1\n",
              "448    -1.141852 -0.581493  ... -0.956462        1\n",
              "636     0.342981 -0.581493  ...  1.255820        0\n",
              "219     0.342981 -0.318475  ...  0.660206        1\n",
              "664     0.639947 -0.219843  ...  0.575118        1\n",
              "\n",
              "[10 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yM0rNXki6AqC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df2.Outcome = df.Outcome"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-o9T9edg6FQy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IvMi-Os6qgl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = df2.Outcome\n",
        "X = df2.drop(['Outcome'],axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nymxLLPH6Qvl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)\n",
        "X_train,X_val,y_train,y_val = train_test_split(X_train,y_train,test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvGN2-W66-VO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a4a44917-9ee9-46c3-95cf-e108a0cf0277"
      },
      "source": [
        "from keras.models import Sequential"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jlga7RTO7Kjg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "b4b49515-d687-4e40-d185-90f6b995fcf3"
      },
      "source": [
        "model = Sequential()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0802 06:57:01.810088 140165700573056 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZhW6GMYHnoF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Dense"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShLVX_h8IAzo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "2d4f1036-1034-4bcc-9650-409999bdecd4"
      },
      "source": [
        "model.add(Dense(32,activation='relu',input_dim=8))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0802 07:11:10.842998 140165700573056 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0802 07:11:10.860547 140165700573056 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VR6ACWJSK25_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(Dense(16,activation='relu'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVWslYjbLAkG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(Dense(1,activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKzagK6CN-AY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "e62b3f47-dc4f-4fc2-a464-22b35fbae4dd"
      },
      "source": [
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0802 07:26:01.712546 140165700573056 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0802 07:26:01.746268 140165700573056 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0802 07:26:01.756022 140165700573056 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-t8D4M_bOQYj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9a2b9a3e-7d78-4b5c-be12-7bd7b37517c4"
      },
      "source": [
        "model.fit(X_train,y_train,epochs=200)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0802 07:26:48.391870 140165700573056 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "491/491 [==============================] - 9s 18ms/step - loss: 0.6058 - acc: 0.7475\n",
            "Epoch 2/200\n",
            "491/491 [==============================] - 0s 132us/step - loss: 0.5665 - acc: 0.7536\n",
            "Epoch 3/200\n",
            "491/491 [==============================] - 0s 136us/step - loss: 0.5342 - acc: 0.7556\n",
            "Epoch 4/200\n",
            "491/491 [==============================] - 0s 166us/step - loss: 0.5090 - acc: 0.7597\n",
            "Epoch 5/200\n",
            "491/491 [==============================] - 0s 149us/step - loss: 0.4907 - acc: 0.7556\n",
            "Epoch 6/200\n",
            "491/491 [==============================] - 0s 142us/step - loss: 0.4779 - acc: 0.7597\n",
            "Epoch 7/200\n",
            "491/491 [==============================] - 0s 146us/step - loss: 0.4681 - acc: 0.7576\n",
            "Epoch 8/200\n",
            "491/491 [==============================] - 0s 156us/step - loss: 0.4611 - acc: 0.7617\n",
            "Epoch 9/200\n",
            "491/491 [==============================] - 0s 158us/step - loss: 0.4556 - acc: 0.7719\n",
            "Epoch 10/200\n",
            "491/491 [==============================] - 0s 169us/step - loss: 0.4506 - acc: 0.7699\n",
            "Epoch 11/200\n",
            "491/491 [==============================] - 0s 164us/step - loss: 0.4471 - acc: 0.7739\n",
            "Epoch 12/200\n",
            "491/491 [==============================] - 0s 151us/step - loss: 0.4428 - acc: 0.7739\n",
            "Epoch 13/200\n",
            "491/491 [==============================] - 0s 153us/step - loss: 0.4399 - acc: 0.7699\n",
            "Epoch 14/200\n",
            "491/491 [==============================] - 0s 132us/step - loss: 0.4363 - acc: 0.7862\n",
            "Epoch 15/200\n",
            "491/491 [==============================] - 0s 152us/step - loss: 0.4334 - acc: 0.7862\n",
            "Epoch 16/200\n",
            "491/491 [==============================] - 0s 148us/step - loss: 0.4308 - acc: 0.7800\n",
            "Epoch 17/200\n",
            "491/491 [==============================] - 0s 160us/step - loss: 0.4282 - acc: 0.7841\n",
            "Epoch 18/200\n",
            "491/491 [==============================] - 0s 143us/step - loss: 0.4266 - acc: 0.7821\n",
            "Epoch 19/200\n",
            "491/491 [==============================] - 0s 141us/step - loss: 0.4238 - acc: 0.7841\n",
            "Epoch 20/200\n",
            "491/491 [==============================] - 0s 140us/step - loss: 0.4206 - acc: 0.7902\n",
            "Epoch 21/200\n",
            "491/491 [==============================] - 0s 158us/step - loss: 0.4189 - acc: 0.7923\n",
            "Epoch 22/200\n",
            "491/491 [==============================] - 0s 148us/step - loss: 0.4168 - acc: 0.7943\n",
            "Epoch 23/200\n",
            "491/491 [==============================] - 0s 144us/step - loss: 0.4144 - acc: 0.7963\n",
            "Epoch 24/200\n",
            "491/491 [==============================] - 0s 161us/step - loss: 0.4129 - acc: 0.7984\n",
            "Epoch 25/200\n",
            "491/491 [==============================] - 0s 168us/step - loss: 0.4100 - acc: 0.8065\n",
            "Epoch 26/200\n",
            "491/491 [==============================] - 0s 166us/step - loss: 0.4090 - acc: 0.8004\n",
            "Epoch 27/200\n",
            "491/491 [==============================] - 0s 158us/step - loss: 0.4065 - acc: 0.7984\n",
            "Epoch 28/200\n",
            "491/491 [==============================] - 0s 152us/step - loss: 0.4045 - acc: 0.8045\n",
            "Epoch 29/200\n",
            "491/491 [==============================] - 0s 159us/step - loss: 0.4035 - acc: 0.8106\n",
            "Epoch 30/200\n",
            "491/491 [==============================] - 0s 186us/step - loss: 0.4014 - acc: 0.8065\n",
            "Epoch 31/200\n",
            "491/491 [==============================] - 0s 155us/step - loss: 0.3990 - acc: 0.8106\n",
            "Epoch 32/200\n",
            "491/491 [==============================] - 0s 160us/step - loss: 0.3974 - acc: 0.8106\n",
            "Epoch 33/200\n",
            "491/491 [==============================] - 0s 159us/step - loss: 0.3948 - acc: 0.8147\n",
            "Epoch 34/200\n",
            "491/491 [==============================] - 0s 172us/step - loss: 0.3943 - acc: 0.8147\n",
            "Epoch 35/200\n",
            "491/491 [==============================] - 0s 160us/step - loss: 0.3932 - acc: 0.8086\n",
            "Epoch 36/200\n",
            "491/491 [==============================] - 0s 159us/step - loss: 0.3917 - acc: 0.8126\n",
            "Epoch 37/200\n",
            "491/491 [==============================] - 0s 158us/step - loss: 0.3892 - acc: 0.8208\n",
            "Epoch 38/200\n",
            "491/491 [==============================] - 0s 168us/step - loss: 0.3868 - acc: 0.8208\n",
            "Epoch 39/200\n",
            "491/491 [==============================] - 0s 162us/step - loss: 0.3859 - acc: 0.8106\n",
            "Epoch 40/200\n",
            "491/491 [==============================] - 0s 172us/step - loss: 0.3838 - acc: 0.8208\n",
            "Epoch 41/200\n",
            "491/491 [==============================] - 0s 163us/step - loss: 0.3829 - acc: 0.8228\n",
            "Epoch 42/200\n",
            "491/491 [==============================] - 0s 183us/step - loss: 0.3807 - acc: 0.8208\n",
            "Epoch 43/200\n",
            "491/491 [==============================] - 0s 192us/step - loss: 0.3796 - acc: 0.8208\n",
            "Epoch 44/200\n",
            "491/491 [==============================] - 0s 147us/step - loss: 0.3774 - acc: 0.8228\n",
            "Epoch 45/200\n",
            "491/491 [==============================] - 0s 155us/step - loss: 0.3760 - acc: 0.8228\n",
            "Epoch 46/200\n",
            "491/491 [==============================] - 0s 151us/step - loss: 0.3746 - acc: 0.8248\n",
            "Epoch 47/200\n",
            "491/491 [==============================] - 0s 159us/step - loss: 0.3734 - acc: 0.8208\n",
            "Epoch 48/200\n",
            "491/491 [==============================] - 0s 168us/step - loss: 0.3721 - acc: 0.8208\n",
            "Epoch 49/200\n",
            "491/491 [==============================] - 0s 168us/step - loss: 0.3702 - acc: 0.8187\n",
            "Epoch 50/200\n",
            "491/491 [==============================] - 0s 163us/step - loss: 0.3689 - acc: 0.8269\n",
            "Epoch 51/200\n",
            "491/491 [==============================] - 0s 153us/step - loss: 0.3675 - acc: 0.8228\n",
            "Epoch 52/200\n",
            "491/491 [==============================] - 0s 164us/step - loss: 0.3673 - acc: 0.8228\n",
            "Epoch 53/200\n",
            "491/491 [==============================] - 0s 158us/step - loss: 0.3647 - acc: 0.8248\n",
            "Epoch 54/200\n",
            "491/491 [==============================] - 0s 160us/step - loss: 0.3635 - acc: 0.8248\n",
            "Epoch 55/200\n",
            "491/491 [==============================] - 0s 190us/step - loss: 0.3624 - acc: 0.8248\n",
            "Epoch 56/200\n",
            "491/491 [==============================] - 0s 177us/step - loss: 0.3611 - acc: 0.8228\n",
            "Epoch 57/200\n",
            "491/491 [==============================] - 0s 168us/step - loss: 0.3596 - acc: 0.8248\n",
            "Epoch 58/200\n",
            "491/491 [==============================] - 0s 155us/step - loss: 0.3586 - acc: 0.8248\n",
            "Epoch 59/200\n",
            "491/491 [==============================] - 0s 155us/step - loss: 0.3576 - acc: 0.8289\n",
            "Epoch 60/200\n",
            "491/491 [==============================] - 0s 159us/step - loss: 0.3563 - acc: 0.8248\n",
            "Epoch 61/200\n",
            "491/491 [==============================] - 0s 160us/step - loss: 0.3553 - acc: 0.8269\n",
            "Epoch 62/200\n",
            "491/491 [==============================] - 0s 169us/step - loss: 0.3540 - acc: 0.8330\n",
            "Epoch 63/200\n",
            "491/491 [==============================] - 0s 159us/step - loss: 0.3521 - acc: 0.8371\n",
            "Epoch 64/200\n",
            "491/491 [==============================] - 0s 161us/step - loss: 0.3514 - acc: 0.8350\n",
            "Epoch 65/200\n",
            "491/491 [==============================] - 0s 156us/step - loss: 0.3502 - acc: 0.8371\n",
            "Epoch 66/200\n",
            "491/491 [==============================] - 0s 161us/step - loss: 0.3496 - acc: 0.8371\n",
            "Epoch 67/200\n",
            "491/491 [==============================] - 0s 170us/step - loss: 0.3489 - acc: 0.8371\n",
            "Epoch 68/200\n",
            "491/491 [==============================] - 0s 190us/step - loss: 0.3467 - acc: 0.8391\n",
            "Epoch 69/200\n",
            "491/491 [==============================] - 0s 161us/step - loss: 0.3462 - acc: 0.8371\n",
            "Epoch 70/200\n",
            "491/491 [==============================] - 0s 155us/step - loss: 0.3457 - acc: 0.8432\n",
            "Epoch 71/200\n",
            "491/491 [==============================] - 0s 168us/step - loss: 0.3445 - acc: 0.8310\n",
            "Epoch 72/200\n",
            "491/491 [==============================] - 0s 158us/step - loss: 0.3427 - acc: 0.8330\n",
            "Epoch 73/200\n",
            "491/491 [==============================] - 0s 156us/step - loss: 0.3418 - acc: 0.8493\n",
            "Epoch 74/200\n",
            "491/491 [==============================] - 0s 165us/step - loss: 0.3407 - acc: 0.8473\n",
            "Epoch 75/200\n",
            "491/491 [==============================] - 0s 158us/step - loss: 0.3396 - acc: 0.8452\n",
            "Epoch 76/200\n",
            "491/491 [==============================] - 0s 154us/step - loss: 0.3390 - acc: 0.8452\n",
            "Epoch 77/200\n",
            "491/491 [==============================] - 0s 152us/step - loss: 0.3376 - acc: 0.8432\n",
            "Epoch 78/200\n",
            "491/491 [==============================] - 0s 167us/step - loss: 0.3360 - acc: 0.8513\n",
            "Epoch 79/200\n",
            "491/491 [==============================] - 0s 181us/step - loss: 0.3356 - acc: 0.8534\n",
            "Epoch 80/200\n",
            "491/491 [==============================] - 0s 183us/step - loss: 0.3341 - acc: 0.8473\n",
            "Epoch 81/200\n",
            "491/491 [==============================] - 0s 161us/step - loss: 0.3332 - acc: 0.8554\n",
            "Epoch 82/200\n",
            "491/491 [==============================] - 0s 159us/step - loss: 0.3320 - acc: 0.8473\n",
            "Epoch 83/200\n",
            "491/491 [==============================] - 0s 161us/step - loss: 0.3314 - acc: 0.8534\n",
            "Epoch 84/200\n",
            "491/491 [==============================] - 0s 158us/step - loss: 0.3306 - acc: 0.8493\n",
            "Epoch 85/200\n",
            "491/491 [==============================] - 0s 157us/step - loss: 0.3299 - acc: 0.8554\n",
            "Epoch 86/200\n",
            "491/491 [==============================] - 0s 171us/step - loss: 0.3278 - acc: 0.8635\n",
            "Epoch 87/200\n",
            "491/491 [==============================] - 0s 154us/step - loss: 0.3272 - acc: 0.8574\n",
            "Epoch 88/200\n",
            "491/491 [==============================] - 0s 164us/step - loss: 0.3260 - acc: 0.8595\n",
            "Epoch 89/200\n",
            "491/491 [==============================] - 0s 152us/step - loss: 0.3267 - acc: 0.8574\n",
            "Epoch 90/200\n",
            "491/491 [==============================] - 0s 153us/step - loss: 0.3238 - acc: 0.8574\n",
            "Epoch 91/200\n",
            "491/491 [==============================] - 0s 161us/step - loss: 0.3231 - acc: 0.8615\n",
            "Epoch 92/200\n",
            "491/491 [==============================] - 0s 151us/step - loss: 0.3217 - acc: 0.8615\n",
            "Epoch 93/200\n",
            "491/491 [==============================] - 0s 177us/step - loss: 0.3209 - acc: 0.8656\n",
            "Epoch 94/200\n",
            "491/491 [==============================] - 0s 161us/step - loss: 0.3203 - acc: 0.8635\n",
            "Epoch 95/200\n",
            "491/491 [==============================] - 0s 160us/step - loss: 0.3199 - acc: 0.8595\n",
            "Epoch 96/200\n",
            "491/491 [==============================] - 0s 161us/step - loss: 0.3172 - acc: 0.8656\n",
            "Epoch 97/200\n",
            "491/491 [==============================] - 0s 157us/step - loss: 0.3170 - acc: 0.8615\n",
            "Epoch 98/200\n",
            "491/491 [==============================] - 0s 157us/step - loss: 0.3163 - acc: 0.8656\n",
            "Epoch 99/200\n",
            "491/491 [==============================] - 0s 162us/step - loss: 0.3152 - acc: 0.8635\n",
            "Epoch 100/200\n",
            "491/491 [==============================] - 0s 152us/step - loss: 0.3144 - acc: 0.8615\n",
            "Epoch 101/200\n",
            "491/491 [==============================] - 0s 158us/step - loss: 0.3130 - acc: 0.8676\n",
            "Epoch 102/200\n",
            "491/491 [==============================] - 0s 155us/step - loss: 0.3128 - acc: 0.8615\n",
            "Epoch 103/200\n",
            "491/491 [==============================] - 0s 170us/step - loss: 0.3107 - acc: 0.8656\n",
            "Epoch 104/200\n",
            "491/491 [==============================] - 0s 175us/step - loss: 0.3100 - acc: 0.8635\n",
            "Epoch 105/200\n",
            "491/491 [==============================] - 0s 163us/step - loss: 0.3086 - acc: 0.8635\n",
            "Epoch 106/200\n",
            "491/491 [==============================] - 0s 196us/step - loss: 0.3067 - acc: 0.8697\n",
            "Epoch 107/200\n",
            "491/491 [==============================] - 0s 165us/step - loss: 0.3068 - acc: 0.8697\n",
            "Epoch 108/200\n",
            "491/491 [==============================] - 0s 149us/step - loss: 0.3052 - acc: 0.8717\n",
            "Epoch 109/200\n",
            "491/491 [==============================] - 0s 156us/step - loss: 0.3051 - acc: 0.8717\n",
            "Epoch 110/200\n",
            "491/491 [==============================] - 0s 151us/step - loss: 0.3033 - acc: 0.8717\n",
            "Epoch 111/200\n",
            "491/491 [==============================] - 0s 162us/step - loss: 0.3015 - acc: 0.8717\n",
            "Epoch 112/200\n",
            "491/491 [==============================] - 0s 158us/step - loss: 0.3010 - acc: 0.8758\n",
            "Epoch 113/200\n",
            "491/491 [==============================] - 0s 154us/step - loss: 0.3012 - acc: 0.8676\n",
            "Epoch 114/200\n",
            "491/491 [==============================] - 0s 158us/step - loss: 0.2994 - acc: 0.8717\n",
            "Epoch 115/200\n",
            "491/491 [==============================] - 0s 160us/step - loss: 0.2989 - acc: 0.8737\n",
            "Epoch 116/200\n",
            "491/491 [==============================] - 0s 160us/step - loss: 0.2970 - acc: 0.8819\n",
            "Epoch 117/200\n",
            "491/491 [==============================] - 0s 163us/step - loss: 0.2959 - acc: 0.8778\n",
            "Epoch 118/200\n",
            "491/491 [==============================] - 0s 174us/step - loss: 0.2945 - acc: 0.8737\n",
            "Epoch 119/200\n",
            "491/491 [==============================] - 0s 177us/step - loss: 0.2941 - acc: 0.8798\n",
            "Epoch 120/200\n",
            "491/491 [==============================] - 0s 175us/step - loss: 0.2935 - acc: 0.8778\n",
            "Epoch 121/200\n",
            "491/491 [==============================] - 0s 181us/step - loss: 0.2928 - acc: 0.8819\n",
            "Epoch 122/200\n",
            "491/491 [==============================] - 0s 177us/step - loss: 0.2908 - acc: 0.8758\n",
            "Epoch 123/200\n",
            "491/491 [==============================] - 0s 169us/step - loss: 0.2896 - acc: 0.8737\n",
            "Epoch 124/200\n",
            "491/491 [==============================] - 0s 169us/step - loss: 0.2881 - acc: 0.8758\n",
            "Epoch 125/200\n",
            "491/491 [==============================] - 0s 163us/step - loss: 0.2887 - acc: 0.8737\n",
            "Epoch 126/200\n",
            "491/491 [==============================] - 0s 176us/step - loss: 0.2862 - acc: 0.8758\n",
            "Epoch 127/200\n",
            "491/491 [==============================] - 0s 171us/step - loss: 0.2856 - acc: 0.8798\n",
            "Epoch 128/200\n",
            "491/491 [==============================] - 0s 161us/step - loss: 0.2861 - acc: 0.8737\n",
            "Epoch 129/200\n",
            "491/491 [==============================] - 0s 171us/step - loss: 0.2848 - acc: 0.8819\n",
            "Epoch 130/200\n",
            "491/491 [==============================] - 0s 171us/step - loss: 0.2824 - acc: 0.8798\n",
            "Epoch 131/200\n",
            "491/491 [==============================] - 0s 161us/step - loss: 0.2818 - acc: 0.8839\n",
            "Epoch 132/200\n",
            "491/491 [==============================] - 0s 153us/step - loss: 0.2837 - acc: 0.8819\n",
            "Epoch 133/200\n",
            "491/491 [==============================] - 0s 152us/step - loss: 0.2835 - acc: 0.8778\n",
            "Epoch 134/200\n",
            "491/491 [==============================] - 0s 162us/step - loss: 0.2782 - acc: 0.8819\n",
            "Epoch 135/200\n",
            "491/491 [==============================] - 0s 150us/step - loss: 0.2773 - acc: 0.8758\n",
            "Epoch 136/200\n",
            "491/491 [==============================] - 0s 160us/step - loss: 0.2773 - acc: 0.8819\n",
            "Epoch 137/200\n",
            "491/491 [==============================] - 0s 152us/step - loss: 0.2759 - acc: 0.8798\n",
            "Epoch 138/200\n",
            "491/491 [==============================] - 0s 153us/step - loss: 0.2746 - acc: 0.8859\n",
            "Epoch 139/200\n",
            "491/491 [==============================] - 0s 168us/step - loss: 0.2734 - acc: 0.8819\n",
            "Epoch 140/200\n",
            "491/491 [==============================] - 0s 162us/step - loss: 0.2716 - acc: 0.8819\n",
            "Epoch 141/200\n",
            "491/491 [==============================] - 0s 151us/step - loss: 0.2713 - acc: 0.8859\n",
            "Epoch 142/200\n",
            "491/491 [==============================] - 0s 157us/step - loss: 0.2723 - acc: 0.8798\n",
            "Epoch 143/200\n",
            "491/491 [==============================] - 0s 171us/step - loss: 0.2698 - acc: 0.8839\n",
            "Epoch 144/200\n",
            "491/491 [==============================] - 0s 173us/step - loss: 0.2690 - acc: 0.8798\n",
            "Epoch 145/200\n",
            "491/491 [==============================] - 0s 163us/step - loss: 0.2670 - acc: 0.8839\n",
            "Epoch 146/200\n",
            "491/491 [==============================] - 0s 189us/step - loss: 0.2666 - acc: 0.8900\n",
            "Epoch 147/200\n",
            "491/491 [==============================] - 0s 166us/step - loss: 0.2662 - acc: 0.8839\n",
            "Epoch 148/200\n",
            "491/491 [==============================] - 0s 159us/step - loss: 0.2654 - acc: 0.8859\n",
            "Epoch 149/200\n",
            "491/491 [==============================] - 0s 161us/step - loss: 0.2634 - acc: 0.8900\n",
            "Epoch 150/200\n",
            "491/491 [==============================] - 0s 155us/step - loss: 0.2642 - acc: 0.8880\n",
            "Epoch 151/200\n",
            "491/491 [==============================] - 0s 163us/step - loss: 0.2618 - acc: 0.8839\n",
            "Epoch 152/200\n",
            "491/491 [==============================] - 0s 172us/step - loss: 0.2612 - acc: 0.8859\n",
            "Epoch 153/200\n",
            "491/491 [==============================] - 0s 156us/step - loss: 0.2591 - acc: 0.8921\n",
            "Epoch 154/200\n",
            "491/491 [==============================] - 0s 155us/step - loss: 0.2584 - acc: 0.8859\n",
            "Epoch 155/200\n",
            "491/491 [==============================] - 0s 162us/step - loss: 0.2571 - acc: 0.8900\n",
            "Epoch 156/200\n",
            "491/491 [==============================] - 0s 172us/step - loss: 0.2566 - acc: 0.8921\n",
            "Epoch 157/200\n",
            "491/491 [==============================] - 0s 153us/step - loss: 0.2564 - acc: 0.8941\n",
            "Epoch 158/200\n",
            "491/491 [==============================] - 0s 154us/step - loss: 0.2555 - acc: 0.8880\n",
            "Epoch 159/200\n",
            "491/491 [==============================] - 0s 158us/step - loss: 0.2535 - acc: 0.8941\n",
            "Epoch 160/200\n",
            "491/491 [==============================] - 0s 167us/step - loss: 0.2536 - acc: 0.8961\n",
            "Epoch 161/200\n",
            "491/491 [==============================] - 0s 154us/step - loss: 0.2525 - acc: 0.8941\n",
            "Epoch 162/200\n",
            "491/491 [==============================] - 0s 155us/step - loss: 0.2500 - acc: 0.9002\n",
            "Epoch 163/200\n",
            "491/491 [==============================] - 0s 165us/step - loss: 0.2492 - acc: 0.8921\n",
            "Epoch 164/200\n",
            "491/491 [==============================] - 0s 171us/step - loss: 0.2481 - acc: 0.8961\n",
            "Epoch 165/200\n",
            "491/491 [==============================] - 0s 158us/step - loss: 0.2506 - acc: 0.8961\n",
            "Epoch 166/200\n",
            "491/491 [==============================] - 0s 153us/step - loss: 0.2473 - acc: 0.8982\n",
            "Epoch 167/200\n",
            "491/491 [==============================] - 0s 151us/step - loss: 0.2463 - acc: 0.8921\n",
            "Epoch 168/200\n",
            "491/491 [==============================] - 0s 150us/step - loss: 0.2465 - acc: 0.8941\n",
            "Epoch 169/200\n",
            "491/491 [==============================] - 0s 183us/step - loss: 0.2459 - acc: 0.9063\n",
            "Epoch 170/200\n",
            "491/491 [==============================] - 0s 159us/step - loss: 0.2459 - acc: 0.8900\n",
            "Epoch 171/200\n",
            "491/491 [==============================] - 0s 159us/step - loss: 0.2426 - acc: 0.8941\n",
            "Epoch 172/200\n",
            "491/491 [==============================] - 0s 169us/step - loss: 0.2412 - acc: 0.9043\n",
            "Epoch 173/200\n",
            "491/491 [==============================] - 0s 151us/step - loss: 0.2411 - acc: 0.8982\n",
            "Epoch 174/200\n",
            "491/491 [==============================] - 0s 150us/step - loss: 0.2403 - acc: 0.9002\n",
            "Epoch 175/200\n",
            "491/491 [==============================] - 0s 151us/step - loss: 0.2404 - acc: 0.9002\n",
            "Epoch 176/200\n",
            "491/491 [==============================] - 0s 169us/step - loss: 0.2370 - acc: 0.9002\n",
            "Epoch 177/200\n",
            "491/491 [==============================] - 0s 172us/step - loss: 0.2361 - acc: 0.9002\n",
            "Epoch 178/200\n",
            "491/491 [==============================] - 0s 156us/step - loss: 0.2371 - acc: 0.9022\n",
            "Epoch 179/200\n",
            "491/491 [==============================] - 0s 155us/step - loss: 0.2361 - acc: 0.9043\n",
            "Epoch 180/200\n",
            "491/491 [==============================] - 0s 155us/step - loss: 0.2350 - acc: 0.9043\n",
            "Epoch 181/200\n",
            "491/491 [==============================] - 0s 155us/step - loss: 0.2372 - acc: 0.9002\n",
            "Epoch 182/200\n",
            "491/491 [==============================] - 0s 185us/step - loss: 0.2354 - acc: 0.9084\n",
            "Epoch 183/200\n",
            "491/491 [==============================] - 0s 173us/step - loss: 0.2324 - acc: 0.9022\n",
            "Epoch 184/200\n",
            "491/491 [==============================] - 0s 164us/step - loss: 0.2299 - acc: 0.9022\n",
            "Epoch 185/200\n",
            "491/491 [==============================] - 0s 161us/step - loss: 0.2295 - acc: 0.9022\n",
            "Epoch 186/200\n",
            "491/491 [==============================] - 0s 168us/step - loss: 0.2292 - acc: 0.9022\n",
            "Epoch 187/200\n",
            "491/491 [==============================] - 0s 164us/step - loss: 0.2281 - acc: 0.9043\n",
            "Epoch 188/200\n",
            "491/491 [==============================] - 0s 165us/step - loss: 0.2280 - acc: 0.9084\n",
            "Epoch 189/200\n",
            "491/491 [==============================] - 0s 168us/step - loss: 0.2264 - acc: 0.9104\n",
            "Epoch 190/200\n",
            "491/491 [==============================] - 0s 154us/step - loss: 0.2268 - acc: 0.9063\n",
            "Epoch 191/200\n",
            "491/491 [==============================] - 0s 163us/step - loss: 0.2247 - acc: 0.9043\n",
            "Epoch 192/200\n",
            "491/491 [==============================] - 0s 153us/step - loss: 0.2237 - acc: 0.9043\n",
            "Epoch 193/200\n",
            "491/491 [==============================] - 0s 157us/step - loss: 0.2235 - acc: 0.9124\n",
            "Epoch 194/200\n",
            "491/491 [==============================] - 0s 174us/step - loss: 0.2235 - acc: 0.9063\n",
            "Epoch 195/200\n",
            "491/491 [==============================] - 0s 159us/step - loss: 0.2225 - acc: 0.9084\n",
            "Epoch 196/200\n",
            "491/491 [==============================] - 0s 149us/step - loss: 0.2219 - acc: 0.9104\n",
            "Epoch 197/200\n",
            "491/491 [==============================] - 0s 157us/step - loss: 0.2210 - acc: 0.9063\n",
            "Epoch 198/200\n",
            "491/491 [==============================] - 0s 163us/step - loss: 0.2210 - acc: 0.9104\n",
            "Epoch 199/200\n",
            "491/491 [==============================] - 0s 158us/step - loss: 0.2192 - acc: 0.9104\n",
            "Epoch 200/200\n",
            "491/491 [==============================] - 0s 155us/step - loss: 0.2184 - acc: 0.9124\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7a2c7608d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kTQ61-7Obvd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "a8d56000-0e00-4b8c-a72a-47c91eccbfb8"
      },
      "source": [
        "scores = model.evaluate(X_train,y_train)\n",
        "print(\"training accuracy: %.2f%%\\n\" % (scores[1]*100))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "491/491 [==============================] - 0s 128us/step\n",
            "training accuracy: 91.24%\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXqYhx2QQehP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "2fff9f97-6774-48e8-90e5-f35f2d9b17d4"
      },
      "source": [
        "scores = model.evaluate(X_test,y_test)\n",
        "print(\"testing accuracy: %.2f%%\\n\" % (scores[1]*100))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "154/154 [==============================] - 0s 118us/step\n",
            "testing accuracy: 77.92%\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFNkK7WTQ_u1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vh1OyqrKwc1i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "7a755c6b-d886-40a4-f5f1-49be6bb09b3e"
      },
      "source": [
        "y_test_pred = model.predict_classes(X_test)\n",
        "c_matrix = confusion_matrix(y_test,y_test_pred)\n",
        "ax = sns.heatmap(c_matrix,annot=True,xticklabels=['No diabetes','diabetes'],yticklabels=['No diabates','diabetes'],cbar=False,cmap='Blues')\n",
        "ax.set_xlabel(\"Prediction\")\n",
        "ax.set_ylabel(\"Actual\")"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(33.0, 0.5, 'Actual')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEKCAYAAAD6q1UVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAF/NJREFUeJzt3XmYFdWd//H3h71REUUk7nGJJihG\nAY0ao6JG44IalyguccnExD3uCw5BnfgbR50nYxxNcNxw342aUZPgvoVNEVBQJ6LOmMQlgICydPf3\n90dVY0t6uUifvg3n83qefrpu1ak6326Kz62u5VxFBGZmlpdO1S7AzMzan8PfzCxDDn8zsww5/M3M\nMuTwNzPLkMPfzCxDDn8zsww5/M3MMuTwNzPLUJdqF9Ccmq1P9qPH1iHNHHd1tUswa1aPLqiSdj7y\nNzPLkMPfzCxDDn8zsww5/M3MMuTwNzPLkMPfzCxDDn8zsww5/M3MMuTwNzPLkMPfzCxDDn8zsww5\n/M3MMuTwNzPLkMPfzCxDDn8zsww5/M3MMuTwNzPLkMPfzCxDDn8zsww5/M3MMuTwNzPLkMPfzCxD\nDn8zsww5/M3MMuTwNzPLkMPfzCxDDn8zsww5/M3MMuTwNzPLkMPfzCxDDn8zsww5/M3MMuTwNzPL\nkMPfzCxDDn8zsww5/M3MMuTwNzPLkMPfzCxDDn8zsww5/M3MMuTwNzPLkMPfzCxDDn8zsww5/M3M\nMuTwNzPLkMPfzCxDDn8zsww5/M3MMuTwNzPLUJdqF2Bt75QjhnDM93cgIpj61vsc//Nb+eX5P2Bg\n//UR4q13P+DHI25h3mcLq12qZWbEhefzzNNPsfrqfbj/t48snn/7bbdw1x230alTZ3baaWdOP+uc\nKlaZB4f/Cmbtvqty4rCd2fqgXzB/wSJuvew4DtlzEOdccT9z5s0H4LIzD+SEw3bmihv/UOVqLTf7\nH3Agww4/kuHnn7t43tg/vcRTT4zhnvsfolu3bnz88cdVrDAf7XLaR1InSb3aoy+DLp07U9O9K507\nd6KmRzf+8uHsxcEP0KN7VyKiihVargYN3oZeq676hXn33HUHx/3T8XTr1g2APn36VKO07CQLf0m3\nS+olaSVgCvCapLNT9WeF9z+czS9Hj+GNRy/h7T/8gk/mfsaYl6YB8JuRRzLjj5ey2Vf7cc2dT1e5\nUrPCOzNmMHHCeI447BCOO/pIpkx+tdolZSHlkX//iPgEOAB4FNgQOCphfwb0XqWGfXcZwDf2/Tkb\n7TGclWq6cdje2wDwk5G3stEew5n29l85eI9BVa7UrFBbV8fs2bO59Y67Of3Mczj7zJ/5L9N2kDL8\nu0rqShH+D0XEIqDFf1FJx0saL2l87UdTE5a24tr1W19nxvsf89HMudTW1vPgE5PY7psbLl5eXx/c\n8/gEDthtqypWafa5fv36sdvu30USA7bckk6dOjFz5sxql7XCSxn+vwFmACsBz0jaAPikpRUiYlRE\nDI6IwV3W2DxhaSuu9/76d7YdsCE1PboCMGTbzZj+9t/YaL01FrfZd+cteWPG36pVotkXDNltd8aN\n/RMAM2a8zaJFi1httdWqXNWKT+3555WkLhFRW0nbmq1P9t99X9KFP92bg/cYSG1dPZOm/S8nXHw7\nj406hVVWqkGCyW/8H6deetcXLgJb5WaOu7raJSy3zj3rDMaPG8usWTNZvU8fTjjpFIYO3Z8R/3wB\n06dNo2vXrpxx1jl8a7vtq13qcqtHF1RJu2ThL6kfcCmwdkTsJak/sH1EXF/J+g5/66gc/taRVRr+\nKU/73AQ8Dqxdvn4D+FnC/szMrEIpw3+NiLgbqAcoT/fUJezPzMwqlDL850nqQ3mHj6TtgNkJ+zMz\nswqlHN7hDOAhYGNJzwN9gUMS9mdmZhVKGf5TgZ2BzQAB0/EoomZmHULKMH4xImojYmpETCkf8nox\nYX9mZlahNj/yl/QVYB2gRtLWsPi2o15Az7buz8zMll6K0z57AscA6wL/3mj+HOCCBP2ZmdlSavPw\nj4ibgZslHRQR97X19s3MbNklu+AbEfdJ2gfYHOjRaP7Fqfo0M7PKpBzP/9fAocApFOf9DwE2SNWf\nmZlVLuXdPjtExA+BmRFxEbA9sGnC/szMrEIpw/+z8vunktYGFgFrJezPzMwqlPIhr0ck9QYuByZS\nDPNwXcL+zMysQikv+F5STt4n6RGgR0R4bB8zsw4gWfhL6gGcCOxIcdT/nKRrI8KfIGJmVmUpT/uM\npniw61fl68OBW/DgbmZmVZcy/LeIiP6NXj8p6bWE/ZmZWYVS3u0zsRzDHwBJ3wLGJ+zPzMwqlGJg\nt8kU5/i7Ai9Ierd8vQEwra37MzOzpZfitM++CbZpZmZtKMXAbu80fi1pTRqN7WNmZtWXcmyf/SS9\nCbwNPA3MAB5N1Z+ZmVUu5QXfS4DtgDciYkNgN+ClhP2ZmVmFUob/ooj4GOgkqVNEPAkMTtifmZlV\nKOV9/rMkrQw8A9wm6QNgXsL+zMysQimP/PenGNnzdOAx4H+AoQn7MzOzCqUc2K3xUf7NqfoxM7Ol\nl+Ihr+ciYkdJcyge7lq8CIiI6NXWfZqZ2dJJcZ//juX3Vdp622Zm1jZSHPmv3tLyiPh7W/dpZmZL\nJ8U5/wkUp3sErA/MLKd7A+8CGybo08zMlkKb3+0TERtGxEbAH4GhEbFGRPShGPPn923dn5mZLb2U\nt3puFxH/3fAiIh4FdkjYn5mZVSjlQ17vS7oQuLV8fQTwfsL+zMysQimP/IcBfYEHgPvL6WEJ+zMz\nswqlfMjr78BpqbZvZmZfXrPhL+lhvviQ1hdExH5JKjIzs+RaOvK/ot2qMDOzdtVs+EfE0+1ZiJmZ\ntZ9WL/hK+pqkeyW9JunPDV8VrLeupAckfSjpA0n3SVq3bco2M7NlUcndPjcC1wK1wBBgNJ/fvtna\neg8BawFrAw+X88zMrMoqCf+aiBgDKCLeiYiRwD4VrNc3Im6MiNry6yaK2z3NzKzKKgn/BZI6AW9K\nOlnS94GVK1jvY0lHSupcfh0JfLxM1ZqZWZuoJPxPA3oCpwKDgKOAoytY7zjgB8Bfgb8ABwPHfrky\nzcysLbX6kFdEjCsn57IU4R0R7wB+FsDMrANqNfwlPUkTD3tFxK7NtB/RwuYiIi6pvDwzM0uhkuEd\nzmo03QM4iOLOn+bMa2LeSsCPgD6Aw9/MrMoqOe0zYYlZz0sa20L7KxumJa1Ccc3gWOBO4Mrm1jMz\ns/ZTyWmfxh/L2Iniou+qFaxzBsUwzjcDAyNi5jLUaWZmbUgRzY7dVjSQ3ubzj2WsBd4GLo6I55pp\nfzlwIDAK+M+ImPtlCpszv77lwsyq5Kk3P6x2CWbNGjqgnyppV0n494iI+UvM6x4RC5ppXw8soHij\naLxxUVzw7VVJYQ5/66gc/taRVRr+lVzwfQEYuMS8F5uYB0BEpPyAGDMzawMtjef/FWAdoEbS1hRH\n7gC9KB76MjOz5VRLR/57AscA61LcpdMQ/p8AF6Qty8zMUmppPP+bgZslHRQR97VjTWZmllgl5+cH\nSerd8ELSapL+JWFNZmaWWCXhv1dEzGp4Ud6vv3e6kszMLLVKwr+zpO4NLyTVAN1baG9mZh1cJbd6\n3gaMkXQjxUXfYyie2jUzs+VUJWP7XCZpErA7xUNbjwMbpC7MzMzSqfSBrL9RBP8hwK7A68kqMjOz\n5Fp6yGtTYFj59RFwF8VwEEPaqTYzM0ukpdM+04BngX0j4i0ASae3S1VmZpZUS6d9DqT47N0nJV0n\naTc+f8rXzMyWY82Gf0Q8GBGHAV8HngR+Bqwp6VpJe7RXgWZm1vZaveAbEfMi4vaIGEoxzs/LwLnJ\nKzMzs2SWavjliJgZEaMiYrdUBZmZWXoee9/MLEMOfzOzDDn8zcwy5PA3M8uQw9/MLEMOfzOzDDn8\nzcwy5PA3M8uQw9/MLEMOfzOzDDn8zcwy5PA3M8uQw9/MLEMOfzOzDDn8zcwy5PA3M8uQw9/MLEMO\nfzOzDDn8zcwy5PA3M8uQw9/MLEMOfzOzDDn8zcwy5PA3M8uQw9/MLEMOfzOzDDn8zcwy5PA3M8uQ\nw9/MLEMOfzOzDDn8zcwy5PA3M8tQl2oXYG3vohHDee6Zp1ht9dW5+/6HAZg+7XX+37+MZOHChXTu\n3JlzLxjBFgO2rG6hlp1FCxdwzYhTqF20iPq6Orbcfhf2PPQ4/vPCk1kw/1MA5s6eyXqbfINjz720\nytWu2BQR1a6hSXPm13fMwpYDEyeMo2fPnowYft7i8D/pJz/i8KOO5ts77sRzzz7N6JuuZ9T1o6tc\n6fLpqTc/rHYJy62IYOH8z+he05O62lquvvAkDjjuVDbYdPPFbW6+/EI232ZHBu/yvSpWuvwaOqCf\nKmnn0z4roIGDtqFXr95fmCeJeXPnAjB37lz69l2zGqVZ5iTRvaYnAHV1tdTX1QKfZ9X8T+fx1pSJ\nbLHtd6pUYT6SnvaRtDHwvxGxQNIuwJbA6IiYlbJf+0dnnnM+J5/wY/7j3y+nvr6eG0bfXu2SLFP1\ndXX88twf89Ff/48d9jyADTbtv3jZlLHPssmAQfTouVIVK8xD6iP/+4A6SZsAo4D1gGZTR9LxksZL\nGn/j9aMSl5aXe+++kzPOPo/f/f5Jzjj7PC4ZeWG1S7JMdercmTOuuIF//s29vPfWNP7y7p8XL3v5\nuTFsveNuVawuH6nDvz4iaoHvA7+KiLOBtZprHBGjImJwRAw+9kfHJy4tL488/CC77vZdAHbf43tM\nnTK5yhVZ7mpWWoWNt9ia6S//CYB5n8zivbde5xsDt69yZXlIHf6LJA0DjgYeKed1TdynNaFv3zWZ\nMH4cAOPGvsR6629Q5YosR3Nnz+KzeXMAWLRgAW9OGs+a6xT74qQXn+Ybg7ana7fu1SwxG6lv9TwW\n+Cnwi4h4W9KGwC2J+8zeBeeeyYTxY5k1axZ7f3cXjj/hZC4ccTFX/Nul1NXV0a1bd4aPuLjaZVqG\nPpn5MXdefSlRX0d9BN/cYQj9B+8AwCvPj2HX7x9R5QrzkfxWT0k1wPoRMX1p1vOtntZR+VZP68g6\nxK2ekoYCrwCPla+3kvRQyj7NzKx1qc/5jwS2BWYBRMQrwEaJ+zQzs1Ykv+AbEbOXmFefuE8zM2tF\n6gu+UyUdDnSW9DXgVOCFxH2amVkrUh/5nwJsDiygeLhrNnBa4j7NzKwVqY/894mI4cDwhhmSDgHu\nSdyvmZm1IPWR//kVzjMzs3aU5Mhf0l7A3sA6kq5qtKgXUJuiTzMzq1yq0z7vA+OB/YAJjebPAU5P\n1KeZmVUoSfhHxCRgkqTbyz6W+glfMzNLJ/U5/+/hJ3zNzDqcajzhu2HiPs3MrBXVeMLXA7aZmVWZ\nn/A1M8tQez7hewfwCfCzxH2amVkrkh75R8SnwHBJlxUvY07K/szMrDKpx/PfRtJk4FVgsqRJkgal\n7NPMzFqX+pz/9cCJEfEsgKQdgRuBLRP3a2ZmLUh9zr+uIfgBIuI5PLyDmVnVpRrbZ2A5+bSk31Bc\n7A3gUOCpFH2amVnlUp32uXKJ1z9vNO37/M3MqizV2D5DUmzXzMzaRuoLvkjah+Je/x4N8yLi4tT9\nmplZ81Lf6vlrivP8pwACDgE2SNmnmZm1LvXdPjtExA+BmRFxEbA9sGniPs3MrBWpw/+z8vunktYG\nFgFrJe7TzMxakfqc/yOSegOXAxMp7vT5r8R9mplZK1KP7XNJOXmfpEeAHk0M8WxmZu0s1UNeu0bE\nE5IObGIZEXF/in7NzKwyqY78dwKeAIbyxYe6VL52+JuZVVGq8J8j6QxgCkXYq5zvp3vNzDqAVOG/\ncvl9M2Ab4LcUbwBDgbGJ+jQzswqlGt7hIgBJzwADGz7ERdJI4Hcp+jQzs8qlvs+/H7Cw0euF5Twz\nM6ui1Pf5jwbGSnqgfH0AcFPiPs3MrBWp7/P/haRHge+Us46NiJdT9mlmZq1LPqpnREykeLrXzMw6\niNTn/M3MrANy+JuZZcjhb2aWIYe/mVmGHP5mZhly+JuZZcjhb2aWIYe/mVmGHP5mZhly+JuZZcjh\nb2aWIYe/mVmGHP5mZhlShD9WNweSjo+IUdWuw2xJ3jerw0f++Ti+2gWYNcP7ZhU4/M3MMuTwNzPL\nkMM/Hz6nah2V980q8AVfM7MM+cjfzCxDDv8qkBSSrmz0+ixJI5dhezMkrVFOv9BK269KmrKU2z9G\n0tpftj5bcUkaWe6/F0vavZW2T0kavBTb3krS3stepTXF4V8dC4ADGwK7LUXEDm29TeAYwOFvzYqI\nERHxxzbe7FaAwz8Rh3911FJc5Dp9yQXlkfkTkl6VNEbS+k206SPp95KmSvovQI2WzS2/r1yuP1HS\nZEn7N9pEF0m3SXpd0r2SepbrDJL0tKQJkh6XtJakg4HBwG2SXpFU01S7cv1TJb1W1n5nW/7CrOOQ\nNFzSG5KeAzYr591U7itIGiFpnKQpkkZJUqPVjyr3oymSti3bryTpBkljJb0saX9J3YCLgUPL9oc2\n1a5cf/Ny3ivlvve19v2NLKciwl/t/AXMBXoBM4BVgbOAkeWyh4Gjy+njgAebWP8qYEQ5vQ8QwBoN\n2y6/dwF6ldNrAG9RvEl8tWz/7XLZDWX/XYEXgL7l/EOBG8rpp4DB5XRL7d4HupfTvav9e/ZXkn13\nEDAZ6Fnuw2+V+89NwMFlm9Ubtb8FGNpoP7qunN4JmFJOXwoc2bDfAG8AK1H8xXl1o2011+5XwBHl\n/G5ATbV/T8vDV5cW3hcsoYj4RNJo4FTgs0aLtgcOLKdvAf6tidV3amgTEb+TNLOJNgIulbQTUA+s\nA/Qrl70XEc+X07eWNTwGbAH8oTxQ6wz8pYntbtZCu1cp/kJ4EHiw2R/elmffAR6IiE8BJD3URJsh\nks6heINYHZhKcVADcAdARDwjqZek3sAewH6Szirb9AD+4S/eFtq9CAyXtC5wf0S8uaw/ZA4c/tX1\nS2AicGOCbR8B9AUGRcQiSTMo/rNAceTfWFC8WUyNiO1b2W5L7faheGMaSvGfcUBE1H7ZH8CWP5J6\nANdQ/KX4XnkjQ49GTZrb9w6KiOlLbOtbS26+qXbA65L+RLH//bekn0TEE8v4o6zwfM6/iiLi78Dd\nwI8azX4BOKycPgJ4tolVnwEOB5C0F7BaE21WBT4og38IsEGjZetLagjvw4HngOlA34b5krpK2rxs\nMwdYpZxusp2kTsB6EfEkcG7Z/8oV/Bps+fIMcEB57WcVijf6xhqC/iNJKwMHL7H8UABJOwKzI2I2\n8DhwSsO1AUlbl20b73c0107SRsCfI+Iq4LfAlsv+Y674HP7VdyXFOfkGpwDHSnoVOAo4rYl1LgJ2\nkjSV4vTPu020uQ0YLGky8ENgWqNl04GTJL1O8cZxbUQspPiPepmkScArQMOdQzcBv5b0CsVpnqba\ndQZuLft7GbgqImYt1W/COryImAjcBUwCHgXGLbF8FnAdMIUirMctsYn5kl4Gfs3nBz2XUFxLerXc\npy8p5z8J9G+44NtCux8AU8r9cwtgdBv9uCs0P+FrZpYhH/mbmWXI4W9mliGHv5lZhhz+ZmYZcvib\nmWXI4W8rJEl1jcaQuadh/KIvua1dJD1STu8n6bwW2vaWdGKj12tLuvfL9m2WisPfVlSfRcRWEbEF\nsBD4aeOFKiz1/h8RD0XEv7bQpDdwYqP270fEkg86mVWdw99y8CywiYoRU6eXYypNAdaTtIekF1WM\nfnpP+VQqkr4naZqkiXw+1lLDZxtcXU73k/SApEnl1w7AvwIbl391XK5Gn58gqYekG1WMsvpy+eR1\nwzbvl/SYpDclNTWek1mbcvjbCk1SF2AvipEoAb4GXBMRmwPzgAuB3SNiIDAeOKMcn+Y6iqELBgFf\naWbzVwFPR8Q3gYEUA5idB/xP+VfH2Uu0PwmIiBgADANuLvuCYuz6Q4EBFMMYr7eMP7pZixz+tqKq\nKR/3H08x/MX15fx3IuKlcno7oD/wfNn2aIoxkL4OvB0Rb0bxCPytzfSxK3AtQETUlePUtGTHhm1F\nxDTgHWDTctmYiJgdEfOB1/jiWExmbc6jetqK6rOI2KrxjHI8sHmNZwF/iIhhS7T7wnrtZEGj6Tr8\nf9MS85G/5ewl4NuSNoHFnyi1KcUgeF+VtHHZblgz648BTijX7SxpVf5xJMrGnqUYqZWyn/UpBtkz\na3cOf8tWRHxI8WlRd5SjqL4IfL089XI88Lvygu8HzWziNIoPLpkMTAD6R8THFKeRpki6fIn21wCd\nyvZ3AcdExALMqsCjepqZZchH/mZmGXL4m5llyOFvZpYhh7+ZWYYc/mZmGXL4m5llyOFvZpYhh7+Z\nWYb+Pwfk+MYs/PAfAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCYTFmVcxneU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1h8bH0YW0Uve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test_pred_probs = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jwoFInk0hL1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FPR,TPR,_ = roc_curve(y_test,y_test_pred_probs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWik75Fv0tXn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "15405657-1ce2-466c-f689-05b3b8e71576"
      },
      "source": [
        "plt.plot(FPR,TPR)\n",
        "plt.plot([0,1],[0,1],'--',color='black')\n",
        "plt.title('ROC Curve')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'True Positive Rate')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymy6P0Rv1SVu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2MnTz-D2jRv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}